{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.experimental import enable_iterative_imputer, enable_halving_search_cv\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.impute import *\n",
    "from imblearn.combine import *\n",
    "from imblearn.over_sampling import *\n",
    "from imblearn.under_sampling import *\n",
    "from imblearn.combine import *\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import *\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.feature_selection import *\n",
    "from scipy.stats import *\n",
    "\n",
    "import missingno as msno\n",
    "import prince\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(estimator, param_distribution, X, y, X_test, idcol, modelname = 'Model', cv = StratifiedKFold(5), n_iter = 50):\n",
    "  cdt = dt.today().strftime('%Y-%m-%d')\n",
    "  rs = HalvingRandomSearchCV(\n",
    "      estimator=estimator,\n",
    "      param_distributions=param_distribution,\n",
    "      scoring='f1',\n",
    "      cv=cv,\n",
    "      verbose=2,\n",
    "      random_state=423323,\n",
    "      n_jobs=-1\n",
    "  )\n",
    "\n",
    "  rs.fit(X, y)\n",
    "  filename = modelname+'-'+str(cdt)+'-result.csv'\n",
    "  pd.DataFrame(rs.cv_results_).to_csv(filename, index = False)\n",
    "  print(rs.best_estimator_)\n",
    "  \n",
    "  model = rs.best_estimator_\n",
    "  cal = CalibratedClassifierCV(model)\n",
    "  cal.fit(X, y)\n",
    "\n",
    "  # Calibrated\n",
    "  ypred = cal.predict(X_test)\n",
    "  ypred = ['Layak Minum' if i == 0 else 'Tidak Layak Minum' for i in ypred]\n",
    "  submission = pd.DataFrame({\n",
    "      'id' : idcol,\n",
    "      'DC201' : ypred\n",
    "  })\n",
    "  filename = modelname+'-calibrated-'+str(cdt)+'submission.csv'\n",
    "  submission.to_csv(filename, index = False)\n",
    "\n",
    "  # Non Calibrated\n",
    "  ypred2 = model.predict(X_test)\n",
    "  ypred2 = ['Layak Minum' if i == 0 else 'Tidak Layak Minum' for i in ypred2]\n",
    "  submission = pd.DataFrame({\n",
    "      'id' : idcol,\n",
    "      'DC201' : ypred2\n",
    "  })\n",
    "\n",
    "  filename = modelname+'-'+str(cdt)+'submission.csv'\n",
    "  submission.to_csv(filename, index = False)\n",
    "\n",
    "  return(pd.DataFrame(rs.cv_results_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t-muhammad.zaki/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/prince/ca.py:82: RuntimeWarning: divide by zero encountered in power\n",
      "  S = sparse.diags(r**-0.5) @ (X - np.outer(r, c)) @ sparse.diags(c**-0.5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# MCA\u001b[39;00m\n\u001b[1;32m     29\u001b[0m mca \u001b[39m=\u001b[39m prince\u001b[39m.\u001b[39mMCA(n_components\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m mca\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m     31\u001b[0m mca\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Scale\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/prince/mca.py:35\u001b[0m, in \u001b[0;36mMCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ_ \u001b[39m=\u001b[39m one_hot\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[39m# Apply CA to the indicator matrix\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(one_hot)\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/prince/ca.py:85\u001b[0m, in \u001b[0;36mCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m S \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mdiags(r\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m) \u001b[39m@\u001b[39m (X \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mouter(r, c)) \u001b[39m@\u001b[39m sparse\u001b[39m.\u001b[39mdiags(c\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[39m# Compute SVD on the standardised residuals\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msvd_ \u001b[39m=\u001b[39m svd\u001b[39m.\u001b[39;49mcompute_svd(\n\u001b[1;32m     86\u001b[0m     X\u001b[39m=\u001b[39;49mS,\n\u001b[1;32m     87\u001b[0m     n_components\u001b[39m=\u001b[39;49m\u001b[39mmin\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components, \u001b[39mmin\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[1;32m     88\u001b[0m     n_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter,\n\u001b[1;32m     89\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m     90\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine,\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     93\u001b[0m \u001b[39m# Compute total inertia\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_inertia_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mij,ji->\u001b[39m\u001b[39m\"\u001b[39m, S, S\u001b[39m.\u001b[39mT)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/prince/svd.py:41\u001b[0m, in \u001b[0;36mcompute_svd\u001b[0;34m(X, n_components, n_iter, random_state, engine)\u001b[0m\n\u001b[1;32m     39\u001b[0m     V \u001b[39m=\u001b[39m V[:n_components, :]\n\u001b[1;32m     40\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msklearn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     U, s, V \u001b[39m=\u001b[39m extmath\u001b[39m.\u001b[39;49mrandomized_svd(\n\u001b[1;32m     42\u001b[0m         X, n_components\u001b[39m=\u001b[39;49mn_components, n_iter\u001b[39m=\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49mrandom_state\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mengine has to be one of (\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfbpca\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mscipy\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msklearn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:446\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n\u001b[1;32m    443\u001b[0m     \u001b[39m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     M \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 446\u001b[0m Q \u001b[39m=\u001b[39m randomized_range_finder(\n\u001b[1;32m    447\u001b[0m     M,\n\u001b[1;32m    448\u001b[0m     size\u001b[39m=\u001b[39;49mn_random,\n\u001b[1;32m    449\u001b[0m     n_iter\u001b[39m=\u001b[39;49mn_iter,\n\u001b[1;32m    450\u001b[0m     power_iteration_normalizer\u001b[39m=\u001b[39;49mpower_iteration_normalizer,\n\u001b[1;32m    451\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    452\u001b[0m )\n\u001b[1;32m    454\u001b[0m \u001b[39m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[1;32m    455\u001b[0m B \u001b[39m=\u001b[39m safe_sparse_dot(Q\u001b[39m.\u001b[39mT, M)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:274\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    272\u001b[0m     Q \u001b[39m=\u001b[39m safe_sparse_dot(A\u001b[39m.\u001b[39mT, Q)\n\u001b[1;32m    273\u001b[0m \u001b[39melif\u001b[39;00m power_iteration_normalizer \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLU\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 274\u001b[0m     Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mlu(safe_sparse_dot(A, Q), permute_l\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    275\u001b[0m     Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mlu(safe_sparse_dot(A\u001b[39m.\u001b[39mT, Q), permute_l\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[39melif\u001b[39;00m power_iteration_normalizer \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mQR\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/scipy/linalg/_decomp_lu.py:213\u001b[0m, in \u001b[0;36mlu\u001b[0;34m(a, permute_l, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mCompute pivoted LU decomposition of a matrix.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39mif\u001b[39;00m check_finite:\n\u001b[0;32m--> 213\u001b[0m     a1 \u001b[39m=\u001b[39m asarray_chkfinite(a)\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     a1 \u001b[39m=\u001b[39m asarray(a)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/numpy/lib/function_base.py:628\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    626\u001b[0m a \u001b[39m=\u001b[39m asarray(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mchar \u001b[39min\u001b[39;00m typecodes[\u001b[39m'\u001b[39m\u001b[39mAllFloat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    629\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# Read\n",
    "df = pd.read_csv('train.csv')\n",
    "df['DC201'] = [0 if i == 'Layak Minum' else 1 for i in df['DC201']]\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df.head()\n",
    "\n",
    "# Modify\n",
    "X = df.drop(['id','DC109', 'DC201'], axis = 1)\n",
    "y = df['DC201']\n",
    "X_test = df_test.drop(['DC109', 'id'], axis = 1)\n",
    "X_test_id = df_test['id']\n",
    "\n",
    "# Replace low frequency\n",
    "threshold = 0.02 # Anything that occurs less than this will be set as missing values.\n",
    "for col in X.columns:\n",
    "  value_counts = X[col].value_counts(normalize=True) # Specific column \n",
    "  to_remove = value_counts[value_counts <= threshold].index\n",
    "  X[col].replace(to_remove, np.nan, inplace=True)\n",
    "\n",
    "# Fill Missing with IterativeImputer\n",
    "print('Filling missing values...')\n",
    "impute = IterativeImputer(max_iter=100, min_value = 0, max_value = 99, random_state=13323, initial_strategy='constant')\n",
    "impute.set_output(transform ='pandas')\n",
    "X = impute.fit_transform(X)\n",
    "X_test =impute.transform(X_test)\n",
    "\n",
    "# MCA\n",
    "mca = prince.MCA(n_components=13)\n",
    "mca.fit_transform(X)\n",
    "mca.transform(X_test)\n",
    "\n",
    "# Scale\n",
    "minmax = MaxAbsScaler()\n",
    "X = minmax.fit_transform(X)\n",
    "X_test = minmax.transform(X_test)\n",
    "\n",
    "# Print\n",
    "print(X.shape)\n",
    "\n",
    "# Save\n",
    "pd.DataFrame(X).to_csv('X_preprocess_2023-05-19.csv', index = False)\n",
    "pd.DataFrame(X_test).to_csv('X_test_preprocess_2023-05-19.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 8\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 12\n",
      "max_resources_: 35973\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2997\n",
      "n_resources: 12\n",
      "Fitting 3 folds for each of 2997 candidates, totalling 8991 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Hyperparameter grid\u001b[39;00m\n\u001b[1;32m      8\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlgbmclassifier__boosting_type\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mgbdt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdart\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m#\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlgbmclassifier__num_leaves\u001b[39m\u001b[39m'\u001b[39m: randint(\u001b[39m50\u001b[39m, \u001b[39m750\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlgbmclassifier__scale_pos_weight\u001b[39m\u001b[39m'\u001b[39m: uniform(\u001b[39m0.5\u001b[39m, \u001b[39m1.5\u001b[39m),\n\u001b[1;32m     23\u001b[0m }\n\u001b[0;32m---> 25\u001b[0m res \u001b[39m=\u001b[39m tune(clf, params, X, y, X_test, df_test[\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m], modelname \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mlgbm_final\u001b[39;49m\u001b[39m'\u001b[39;49m, cv \u001b[39m=\u001b[39;49m StratifiedKFold(\u001b[39m3\u001b[39;49m), n_iter \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mtune\u001b[0;34m(estimator, param_distribution, X, y, X_test, idcol, modelname, cv, n_iter)\u001b[0m\n\u001b[1;32m      2\u001b[0m cdt \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m rs \u001b[39m=\u001b[39m HalvingRandomSearchCV(\n\u001b[1;32m      4\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m      5\u001b[0m     param_distributions\u001b[39m=\u001b[39mparam_distribution,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m rs\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     14\u001b[0m filename \u001b[39m=\u001b[39m modelname\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(cdt)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-result.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     15\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(rs\u001b[39m.\u001b[39mcv_results_)\u001b[39m.\u001b[39mto_csv(filename, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search_successive_halving.py:273\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input_parameters(\n\u001b[1;32m    266\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    267\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[1;32m    268\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[1;32m    269\u001b[0m )\n\u001b[1;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples_orig \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 273\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    275\u001b[0m \u001b[39m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_results_[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_index_]\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search_successive_halving.py:378\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    371\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checked_cv_orig\n\u001b[1;32m    373\u001b[0m more_results \u001b[39m=\u001b[39m {\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: [itr] \u001b[39m*\u001b[39m n_candidates,\n\u001b[1;32m    375\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_resources\u001b[39m\u001b[39m\"\u001b[39m: [n_resources] \u001b[39m*\u001b[39m n_candidates,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m results \u001b[39m=\u001b[39m evaluate_candidates(\n\u001b[1;32m    379\u001b[0m     candidate_params, cv, more_results\u001b[39m=\u001b[39;49mmore_results\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    382\u001b[0m n_candidates_to_keep \u001b[39m=\u001b[39m ceil(n_candidates \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor)\n\u001b[1;32m    383\u001b[0m candidate_params \u001b[39m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Desktop/sklearn-aio/sklearn-aio/.venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "clf = make_pipeline(\n",
    "    SMOTEENN(),\n",
    "    LGBMClassifier()\n",
    ")\n",
    "\n",
    "# Hyperparameter grid\n",
    "params = {\n",
    "    'lgbmclassifier__boosting_type': ['gbdt', 'dart'], #\n",
    "    'lgbmclassifier__num_leaves': randint(50, 750),\n",
    "    'lgbmclassifier__max_depth': [-1, 5, 10, 15, 20, 25], #can vary\n",
    "    'lgbmclassifier__learning_rate': uniform(0.009, 0.28), #\n",
    "    'lgbmclassifier__n_estimators': randint(30, 550), # can be extended\n",
    "    'lgbmclassifier__min_child_samples': randint(18, 250),\n",
    "    'lgbmclassifier__reg_alpha': uniform(1, 7),\n",
    "    'lgbmclassifier__reg_lambda': uniform(1, 7),\n",
    "    'lgbmclassifier__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'lgbmclassifier__subsample': uniform(0.45, 0.55),\n",
    "    'lgbmclassifier__subsample_freq': randint(1, 10), # can be extended\n",
    "    'lgbmclassifier__min_split_gain': uniform(0, 1),\n",
    "    'lgbmclassifier__min_child_weight': uniform(1, 9),\n",
    "    'lgbmclassifier__scale_pos_weight': uniform(0.5, 1.5),\n",
    "}\n",
    "\n",
    "res = tune(clf, params, X, y, X_test, df_test['id'], modelname = 'lgbm_final', cv = StratifiedKFold(3), n_iter = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lgbmclassifier__boosting_type</th>\n",
       "      <th>param_lgbmclassifier__colsample_bytree</th>\n",
       "      <th>param_lgbmclassifier__learning_rate</th>\n",
       "      <th>param_lgbmclassifier__max_depth</th>\n",
       "      <th>param_lgbmclassifier__min_child_samples</th>\n",
       "      <th>param_lgbmclassifier__min_child_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>param_lgbmclassifier__scale_pos_weight</th>\n",
       "      <th>param_lgbmclassifier__subsample</th>\n",
       "      <th>param_lgbmclassifier__subsample_freq</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mean_fit_time, std_fit_time, mean_score_time, std_score_time, param_lgbmclassifier__boosting_type, param_lgbmclassifier__colsample_bytree, param_lgbmclassifier__learning_rate, param_lgbmclassifier__max_depth, param_lgbmclassifier__min_child_samples, param_lgbmclassifier__min_child_weight, param_lgbmclassifier__min_split_gain, param_lgbmclassifier__n_estimators, param_lgbmclassifier__num_leaves, param_lgbmclassifier__reg_alpha, param_lgbmclassifier__reg_lambda, param_lgbmclassifier__scale_pos_weight, param_lgbmclassifier__subsample, param_lgbmclassifier__subsample_freq, params, split0_test_score, split1_test_score, split2_test_score, mean_test_score, std_test_score, rank_test_score]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res['mean_test_score'] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning\n",
    "clf = make_pipeline(\n",
    "    SMOTEENN(),\n",
    "    LGBMClassifier()\n",
    ")\n",
    "\n",
    "# Hyperparameter grid\n",
    "params = {'lgbmclassifier__boosting_type': 'dart',\n",
    " 'lgbmclassifier__colsample_bytree': 0.7745494227163026,\n",
    " 'lgbmclassifier__learning_rate': 0.04968043132716672,\n",
    " 'lgbmclassifier__max_depth': -1,\n",
    " 'lgbmclassifier__min_child_samples': 206,\n",
    " 'lgbmclassifier__min_child_weight': 8.283022569902414,\n",
    " 'lgbmclassifier__min_split_gain': 0.9424678207920167,\n",
    " 'lgbmclassifier__n_estimators': 169,\n",
    " 'lgbmclassifier__num_leaves': 350,\n",
    " 'lgbmclassifier__reg_alpha': 2.259442111644672,\n",
    " 'lgbmclassifier__reg_lambda': 6.486406050011509,\n",
    " 'lgbmclassifier__scale_pos_weight': 0.8287661198398674,\n",
    " 'lgbmclassifier__subsample': 0.7170114552756686,\n",
    " 'lgbmclassifier__subsample_freq': 6}\n",
    "\n",
    "clf.set_params(**params)\n",
    "clf.fit(X, y)\n",
    "ypred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9577\n",
       "1    2413\n",
       "Name: DC201, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\n",
    "    'id' : pd.read_csv('test.csv')[\"id\"],\n",
    "    'DC201' : ypred\n",
    "})\n",
    "result['DC201'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18115024, 0.02213001, 0.        , 0.20823074, 0.2540705 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LGBMClassifier(), X, y, cv = StratifiedKFold(5), scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11452\n",
       "1      538\n",
       "Name: DC201, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LGBMClassifier()\n",
    "clf.fit(X, y)\n",
    "ypred = clf.predict(X_test)\n",
    "result = pd.DataFrame({\n",
    "    'id' : pd.read_csv('test.csv')[\"id\"],\n",
    "    'DC201' : ypred\n",
    "})\n",
    "result['DC201'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layak Minum          11851\n",
       "Tidak Layak Minum      139\n",
       "Name: DC201, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('lgbm_advanced-calibrated-2023-05-18submission.csv')['DC201'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
